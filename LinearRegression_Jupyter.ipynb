{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14a9548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# load dataset\n",
    "alltopcountries = pd.read_csv(\"VossMaria_CPE_590_Project/VossMaria_CPE_590_Project/Datasets/top26_numlabels.csv\")\n",
    "\n",
    "# Create the Logistic Regression model\n",
    "x = alltopcountries[['Material Number Labels', 'Geo Number Labels', 'OBS_VALUE']].to_numpy() # features\n",
    "y = alltopcountries[['Partner Number Labels']].to_numpy().ravel() # output\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=16)\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression(random_state=16, max_iter=1000)\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76ec9a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07126756330302803\n"
     ]
    }
   ],
   "source": [
    "print(logreg.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a6305e",
   "metadata": {},
   "source": [
    "Logistic Regression is not a good fit for predicting where the trash will go here, so now, the input class will be the amount of trash taken in, and the output will be which country takes it in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1be5d04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "alltopcountries = pd.read_csv(\"VossMaria_CPE_590_Project/VossMaria_CPE_590_Project/Datasets/top26_numlabels.csv\")\n",
    "\n",
    "# Create the Logistic Regression model\n",
    "x = alltopcountries[['OBS_VALUE']].to_numpy() # features\n",
    "y = alltopcountries[['Partner Number Labels']].to_numpy().ravel() # output\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=16)\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression(random_state=16, max_iter=1000)\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "030b9d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05124351942294688\n"
     ]
    }
   ],
   "source": [
    "print(logreg.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abdb2cb",
   "metadata": {},
   "source": [
    "Even less of a good score! Wow logistic regression is not good for determining which country will take in the trash. Now what if we switch what the output label will be? Going to use Linear regression in order to get the amount of input trash. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa8d05e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 0.0069509252493757945\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "x = alltopcountries[['Material Number Labels', 'Geo Number Labels', 'Partner Number Labels']].to_numpy() # features\n",
    "y = alltopcountries[['OBS_VALUE']].to_numpy().ravel() # output\n",
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(x, y, test_size = 0.3, random_state = 0)\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_Train, Y_Train)\n",
    "print(\"R^2\", regressor.score(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f04da914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = -49466119403.28881\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as sm\n",
    "Y_Pred = regressor.predict(X_Test)\n",
    "# error\n",
    "e= sm.mean_squared_error(Y_Test, Y_Pred)\n",
    "# print accuracy\n",
    "print(\"Accuracy = {}\".format(1-e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d35fc2",
   "metadata": {},
   "source": [
    "Time to try using a lot less features. <br>\n",
    "Going to only keep Glass, Paper, Plastics including Rubber, Metal, Organics, and Textiles from Materials. <br>\n",
    "Going to keep only the EU as a whole instead of each specific country. <br>\n",
    "Only going to keep the top 10 countries importing trash from the EU at the moment. <br>\n",
    "Maybe all of this will make a better model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42467b96",
   "metadata": {},
   "source": [
    "Top 10 Countries: <br> \n",
    "'TR': 148062623.0 = Turkiye (Turkey) <br>\n",
    "'CN': 103565534.0 = China including Hong Kong <br>\n",
    "'IN': 31944803.0 = India <br>\n",
    "'UK': 28741386.0 = United Kingdom <br>\n",
    "'CH': 26099504.0 = Switzerland <br>\n",
    "'NO': 18474897.0 = Norway <br>\n",
    "'ID': 14482476.0 = Indonesia <br>\n",
    "'EG': 14327843.0 = Egypt <br>\n",
    "'US': 13218107.0 = United States <br>\n",
    "'HK': 12033537.0 = Hong Kong <br>\n",
    "'PK': 10418970.0 = Pakistan <br>\n",
    "We're going to exclude Hong Kong, though. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b71b4dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Processing this new dataset I need\n",
    "less_materials1 = alltopcountries[alltopcountries['Material Number Labels'] == '245']\n",
    "less_materials2 = alltopcountries[alltopcountries['Material Number Labels'] == '246']\n",
    "less_materials3 = alltopcountries[alltopcountries['Material Number Labels'] == '250']\n",
    "less_materials4 = alltopcountries[alltopcountries['Material Number Labels'] == '253']\n",
    "less_materials5 = alltopcountries[alltopcountries['Material Number Labels'] == '254']\n",
    "less_materials6 = alltopcountries[alltopcountries['Material Number Labels'] == '258']\n",
    "less_materials = pd.concat([less_materials1, less_materials2, less_materials3, less_materials4, less_materials5, less_materials6], ignore_index=True, sort=False)\n",
    "\n",
    "filtercountries1 = less_materials[less_materials['partner'] == 'TR']\n",
    "filtercountries2 = less_materials[less_materials['partner'] == 'CN']\n",
    "filtercountries3 = less_materials[less_materials['partner'] == 'IN']\n",
    "filtercountries4 = less_materials[less_materials['partner'] == 'UK']\n",
    "filtercountries5 = less_materials[less_materials['partner'] == 'CH']\n",
    "filtercountries6 = less_materials[less_materials['partner'] == 'NO']\n",
    "filtercountries7 = less_materials[less_materials['partner'] == 'ID']\n",
    "filtercountries8 = less_materials[less_materials['partner'] == 'EG']\n",
    "filtercountries9 = less_materials[less_materials['partner'] == 'US']\n",
    "filtercountries10 = less_materials[less_materials['partner'] == 'PK']\n",
    "filter_countries = pd.concat([filtercountries1, filtercountries2, filtercountries3, filtercountries4, filtercountries5, filtercountries6, filtercountries7, filtercountries8, filtercountries9, filtercountries10], ignore_index=True, sort=False)\n",
    "\n",
    "allof_EU = filter_countries[filter_countries['geo'] == 'EU27_2020']\n",
    "print(len(less_materials1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de4fcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "x = allof_EU[['Material Number Labels', 'Geo Number Labels', 'Partner Number Labels']].to_numpy() # features\n",
    "y = allof_EU[['OBS_VALUE']].to_numpy().ravel() # output\n",
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(x, y, test_size = 0.3, random_state = 0)\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_Train, Y_Train)\n",
    "print(\"R^2\", regressor.score(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578aaf45",
   "metadata": {},
   "source": [
    "Time to try with one-hot encoding instead of label encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "863aa48b",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 101. GiB for an array with shape (106470, 127642) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder\n\u001b[0;32m      5\u001b[0m encoder \u001b[38;5;241m=\u001b[39m OneHotEncoder()\n\u001b[1;32m----> 6\u001b[0m encoded_results \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mfit_transform(aggregate_trash)\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:1050\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1049\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1050\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_toarray_args(order, out)\n\u001b[0;32m   1051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_base.py:1267\u001b[0m, in \u001b[0;36m_spbase._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 101. GiB for an array with shape (106470, 127642) and data type float64"
     ]
    }
   ],
   "source": [
    "aggregate_trash = alltopcountries.drop(columns=['stk_flow', 'rawmat', 'Material Number Labels', 'partner', 'Partner Number Labels', 'geo', 'Geo Number Labels'])\n",
    "\n",
    "# one-hot-encode using sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "encoded_results = encoder.fit_transform(aggregate_trash).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb86bac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
